2021-08-17T17:50:34.0262406Z stderr F Flag --port has been deprecated, see --secure-port instead.
2021-08-17T17:50:35.0072203Z stderr F I0817 17:50:35.005965       1 serving.go:347] Generated self-signed cert in-memory
2021-08-17T17:50:35.5513919Z stderr F I0817 17:50:35.550488       1 controllermanager.go:175] Version: v1.21.1
2021-08-17T17:50:35.5518431Z stderr F I0817 17:50:35.551406       1 dynamic_cafile_content.go:167] Starting request-header::/etc/kubernetes/pki/front-proxy-ca.crt
2021-08-17T17:50:35.5518707Z stderr F I0817 17:50:35.551474       1 dynamic_cafile_content.go:167] Starting client-ca-bundle::/etc/kubernetes/pki/ca.crt
2021-08-17T17:50:35.5521681Z stderr F I0817 17:50:35.552006       1 secure_serving.go:197] Serving securely on 127.0.0.1:10257
2021-08-17T17:50:35.5526373Z stderr F I0817 17:50:35.552144       1 tlsconfig.go:240] Starting DynamicServingCertificateController
2021-08-17T17:50:35.5526649Z stderr F I0817 17:50:35.552403       1 leaderelection.go:243] attempting to acquire leader lease kube-system/kube-controller-manager...
2021-08-17T17:50:40.5530661Z stderr F E0817 17:50:40.552677       1 leaderelection.go:325] error retrieving resource lock kube-system/kube-controller-manager: Get "https://172.18.0.3:6443/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-controller-manager?timeout=5s": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
2021-08-17T17:50:43.0765754Z stderr F I0817 17:50:43.076435       1 leaderelection.go:253] successfully acquired lease kube-system/kube-controller-manager
2021-08-17T17:50:43.07682Z stderr F I0817 17:50:43.076609       1 event.go:291] "Event occurred" object="kube-system/kube-controller-manager" kind="Lease" apiVersion="coordination.k8s.io/v1" type="Normal" reason="LeaderElection" message="config-control-plane_93326355-efdf-4179-a2ab-546a6ae4bfef became leader"
2021-08-17T17:50:43.6350867Z stderr F I0817 17:50:43.634909       1 shared_informer.go:240] Waiting for caches to sync for tokens
2021-08-17T17:50:43.6449555Z stderr F I0817 17:50:43.644757       1 controllermanager.go:574] Started "attachdetach"
2021-08-17T17:50:43.646203Z stderr F I0817 17:50:43.644922       1 attach_detach_controller.go:327] Starting attach detach controller
2021-08-17T17:50:43.6462495Z stderr F I0817 17:50:43.645005       1 shared_informer.go:240] Waiting for caches to sync for attach detach
2021-08-17T17:50:43.6562017Z stderr F I0817 17:50:43.655939       1 controllermanager.go:574] Started "disruption"
2021-08-17T17:50:43.6563077Z stderr F I0817 17:50:43.655985       1 disruption.go:363] Starting disruption controller
2021-08-17T17:50:43.6563228Z stderr F I0817 17:50:43.656004       1 shared_informer.go:240] Waiting for caches to sync for disruption
2021-08-17T17:50:43.6652914Z stderr F I0817 17:50:43.665062       1 controllermanager.go:574] Started "root-ca-cert-publisher"
2021-08-17T17:50:43.6653293Z stderr F I0817 17:50:43.665270       1 publisher.go:102] Starting root CA certificate configmap publisher
2021-08-17T17:50:43.665344Z stderr F I0817 17:50:43.665299       1 shared_informer.go:240] Waiting for caches to sync for crt configmap
2021-08-17T17:50:43.7070635Z stderr F I0817 17:50:43.706844       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for endpointslices.discovery.k8s.io
2021-08-17T17:50:43.7070878Z stderr F I0817 17:50:43.706927       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for daemonsets.apps
2021-08-17T17:50:43.707101Z stderr F I0817 17:50:43.706958       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for deployments.apps
2021-08-17T17:50:43.7071205Z stderr F I0817 17:50:43.706993       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for events.events.k8s.io
2021-08-17T17:50:43.7071339Z stderr F I0817 17:50:43.707050       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for rolebindings.rbac.authorization.k8s.io
2021-08-17T17:50:43.7071513Z stderr F I0817 17:50:43.707087       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for limitranges
2021-08-17T17:50:43.7072979Z stderr F I0817 17:50:43.707151       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for ingresses.networking.k8s.io
2021-08-17T17:50:43.707331Z stderr F I0817 17:50:43.707239       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for ingresses.extensions
2021-08-17T17:50:43.7073462Z stderr F I0817 17:50:43.707294       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for csistoragecapacities.storage.k8s.io
2021-08-17T17:50:43.707508Z stderr F W0817 17:50:43.707319       1 shared_informer.go:494] resyncPeriod 23h23m53.971225529s is smaller than resyncCheckPeriod 23h43m33.438744215s and the informer has already started. Changing it to 23h43m33.438744215s
2021-08-17T17:50:43.7075257Z stderr F I0817 17:50:43.707397       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for podtemplates
2021-08-17T17:50:43.707534Z stderr F I0817 17:50:43.707429       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for endpoints
2021-08-17T17:50:43.7076098Z stderr F I0817 17:50:43.707458       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for replicasets.apps
2021-08-17T17:50:43.7076239Z stderr F I0817 17:50:43.707479       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for statefulsets.apps
2021-08-17T17:50:43.7076364Z stderr F I0817 17:50:43.707502       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for jobs.batch
2021-08-17T17:50:43.7076496Z stderr F I0817 17:50:43.707534       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for networkpolicies.networking.k8s.io
2021-08-17T17:50:43.7076627Z stderr F I0817 17:50:43.707580       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for poddisruptionbudgets.policy
2021-08-17T17:50:43.7077332Z stderr F I0817 17:50:43.707609       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for leases.coordination.k8s.io
2021-08-17T17:50:43.7078257Z stderr F I0817 17:50:43.707698       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for cronjobs.batch
2021-08-17T17:50:43.707849Z stderr F W0817 17:50:43.707771       1 shared_informer.go:494] resyncPeriod 20h21m18.653122817s is smaller than resyncCheckPeriod 23h43m33.438744215s and the informer has already started. Changing it to 23h43m33.438744215s
2021-08-17T17:50:43.7079385Z stderr F I0817 17:50:43.707835       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for serviceaccounts
2021-08-17T17:50:43.7079556Z stderr F I0817 17:50:43.707894       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for controllerrevisions.apps
2021-08-17T17:50:43.7080041Z stderr F I0817 17:50:43.707925       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for horizontalpodautoscalers.autoscaling
2021-08-17T17:50:43.7080948Z stderr F I0817 17:50:43.707979       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for roles.rbac.authorization.k8s.io
2021-08-17T17:50:43.7082886Z stderr F I0817 17:50:43.708073       1 controllermanager.go:574] Started "resourcequota"
2021-08-17T17:50:43.708553Z stderr F I0817 17:50:43.708391       1 resource_quota_controller.go:273] Starting resource quota controller
2021-08-17T17:50:43.7085665Z stderr F I0817 17:50:43.708425       1 shared_informer.go:240] Waiting for caches to sync for resource quota
2021-08-17T17:50:43.708576Z stderr F I0817 17:50:43.708471       1 resource_quota_monitor.go:304] QuotaMonitor running
2021-08-17T17:50:43.7215306Z stderr F I0817 17:50:43.721292       1 controllermanager.go:574] Started "daemonset"
2021-08-17T17:50:43.7215618Z stderr F I0817 17:50:43.721350       1 daemon_controller.go:285] Starting daemon sets controller
2021-08-17T17:50:43.7215764Z stderr F I0817 17:50:43.721399       1 shared_informer.go:240] Waiting for caches to sync for daemon sets
2021-08-17T17:50:43.7360147Z stderr F I0817 17:50:43.735753       1 shared_informer.go:247] Caches are synced for tokens 
2021-08-17T17:50:43.7429791Z stderr F I0817 17:50:43.742814       1 controllermanager.go:574] Started "horizontalpodautoscaling"
2021-08-17T17:50:43.7430272Z stderr F I0817 17:50:43.742958       1 horizontal.go:169] Starting HPA controller
2021-08-17T17:50:43.7430468Z stderr F I0817 17:50:43.742987       1 shared_informer.go:240] Waiting for caches to sync for HPA
2021-08-17T17:50:43.7585271Z stderr F I0817 17:50:43.758388       1 controllermanager.go:574] Started "csrapproving"
2021-08-17T17:50:43.7587312Z stderr F I0817 17:50:43.758633       1 certificate_controller.go:118] Starting certificate controller "csrapproving"
2021-08-17T17:50:43.7587789Z stderr F I0817 17:50:43.758743       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrapproving
2021-08-17T17:50:43.7719573Z stderr F I0817 17:50:43.771732       1 controllermanager.go:574] Started "ttl"
2021-08-17T17:50:43.7722972Z stderr F I0817 17:50:43.772035       1 ttl_controller.go:121] Starting TTL controller
2021-08-17T17:50:43.7723182Z stderr F I0817 17:50:43.772116       1 shared_informer.go:240] Waiting for caches to sync for TTL
2021-08-17T17:50:43.8410019Z stderr F I0817 17:50:43.840743       1 controllermanager.go:574] Started "bootstrapsigner"
2021-08-17T17:50:43.8410367Z stderr F I0817 17:50:43.840844       1 shared_informer.go:240] Waiting for caches to sync for bootstrap_signer
2021-08-17T17:50:43.9898985Z stderr F I0817 17:50:43.989729       1 controllermanager.go:574] Started "persistentvolume-expander"
2021-08-17T17:50:43.989999Z stderr F I0817 17:50:43.989839       1 expand_controller.go:327] Starting expand controller
2021-08-17T17:50:43.9900237Z stderr F I0817 17:50:43.989864       1 shared_informer.go:240] Waiting for caches to sync for expand
2021-08-17T17:50:44.1423318Z stderr F I0817 17:50:44.142059       1 controllermanager.go:574] Started "pv-protection"
2021-08-17T17:50:44.142377Z stderr F I0817 17:50:44.142163       1 pv_protection_controller.go:83] Starting PV protection controller
2021-08-17T17:50:44.142392Z stderr F I0817 17:50:44.142178       1 shared_informer.go:240] Waiting for caches to sync for PV protection
2021-08-17T17:50:44.3045152Z stderr F I0817 17:50:44.300614       1 controllermanager.go:574] Started "replicationcontroller"
2021-08-17T17:50:44.3045507Z stderr F I0817 17:50:44.300660       1 replica_set.go:182] Starting replicationcontroller controller
2021-08-17T17:50:44.3047398Z stderr F I0817 17:50:44.300777       1 shared_informer.go:240] Waiting for caches to sync for ReplicationController
2021-08-17T17:50:44.4399144Z stderr F I0817 17:50:44.439655       1 controllermanager.go:574] Started "deployment"
2021-08-17T17:50:44.4399387Z stderr F I0817 17:50:44.439764       1 deployment_controller.go:153] "Starting controller" controller="deployment"
2021-08-17T17:50:44.4399477Z stderr F I0817 17:50:44.439794       1 shared_informer.go:240] Waiting for caches to sync for deployment
2021-08-17T17:50:44.59194Z stderr F I0817 17:50:44.591704       1 controllermanager.go:574] Started "statefulset"
2021-08-17T17:50:44.591966Z stderr F I0817 17:50:44.591784       1 stateful_set.go:146] Starting stateful set controller
2021-08-17T17:50:44.5919851Z stderr F I0817 17:50:44.591803       1 shared_informer.go:240] Waiting for caches to sync for stateful set
2021-08-17T17:50:44.6400011Z stderr F I0817 17:50:44.639720       1 controllermanager.go:574] Started "csrcleaner"
2021-08-17T17:50:44.6400458Z stderr F I0817 17:50:44.639808       1 cleaner.go:82] Starting CSR cleaner controller
2021-08-17T17:50:44.8017072Z stderr F I0817 17:50:44.801134       1 controllermanager.go:574] Started "tokencleaner"
2021-08-17T17:50:44.801751Z stderr F I0817 17:50:44.801526       1 tokencleaner.go:118] Starting token cleaner controller
2021-08-17T17:50:44.8017675Z stderr F I0817 17:50:44.801544       1 shared_informer.go:240] Waiting for caches to sync for token_cleaner
2021-08-17T17:50:44.8017899Z stderr F I0817 17:50:44.801559       1 shared_informer.go:247] Caches are synced for token_cleaner 
2021-08-17T17:50:44.9439906Z stderr F I0817 17:50:44.943810       1 controllermanager.go:574] Started "clusterrole-aggregation"
2021-08-17T17:50:44.9447933Z stderr F I0817 17:50:44.943931       1 clusterroleaggregation_controller.go:194] Starting ClusterRoleAggregator
2021-08-17T17:50:44.9448131Z stderr F I0817 17:50:44.943961       1 shared_informer.go:240] Waiting for caches to sync for ClusterRoleAggregator
2021-08-17T17:50:45.2135016Z stderr F I0817 17:50:45.212915       1 controllermanager.go:574] Started "namespace"
2021-08-17T17:50:45.2135313Z stderr F I0817 17:50:45.213020       1 namespace_controller.go:200] Starting namespace controller
2021-08-17T17:50:45.2135496Z stderr F I0817 17:50:45.213035       1 shared_informer.go:240] Waiting for caches to sync for namespace
2021-08-17T17:50:45.343487Z stderr F I0817 17:50:45.343148       1 controllermanager.go:574] Started "serviceaccount"
2021-08-17T17:50:45.3435194Z stderr F I0817 17:50:45.343318       1 serviceaccounts_controller.go:117] Starting service account controller
2021-08-17T17:50:45.3435322Z stderr F I0817 17:50:45.343333       1 shared_informer.go:240] Waiting for caches to sync for service account
2021-08-17T17:50:45.4903056Z stderr F I0817 17:50:45.490067       1 node_lifecycle_controller.go:377] Sending events to api server.
2021-08-17T17:50:45.4905407Z stderr F I0817 17:50:45.490365       1 taint_manager.go:163] "Sending events to api server"
2021-08-17T17:50:45.4905799Z stderr F I0817 17:50:45.490455       1 node_lifecycle_controller.go:505] Controller will reconcile labels.
2021-08-17T17:50:45.4906018Z stderr F I0817 17:50:45.490504       1 controllermanager.go:574] Started "nodelifecycle"
2021-08-17T17:50:45.4906783Z stderr F I0817 17:50:45.490596       1 node_lifecycle_controller.go:539] Starting node controller
2021-08-17T17:50:45.4906934Z stderr F I0817 17:50:45.490624       1 shared_informer.go:240] Waiting for caches to sync for taint
2021-08-17T17:50:45.6425376Z stderr F I0817 17:50:45.642278       1 controllermanager.go:574] Started "persistentvolume-binder"
2021-08-17T17:50:45.6426304Z stderr F I0817 17:50:45.642458       1 pv_controller_base.go:308] Starting persistent volume controller
2021-08-17T17:50:45.6426628Z stderr F I0817 17:50:45.642488       1 shared_informer.go:240] Waiting for caches to sync for persistent volume
2021-08-17T17:50:45.794626Z stderr F I0817 17:50:45.794274       1 controllermanager.go:574] Started "ttl-after-finished"
2021-08-17T17:50:45.7946714Z stderr F I0817 17:50:45.794324       1 ttlafterfinished_controller.go:109] Starting TTL after finished controller
2021-08-17T17:50:45.794682Z stderr F I0817 17:50:45.794340       1 shared_informer.go:240] Waiting for caches to sync for TTL after finished
2021-08-17T17:50:45.9452572Z stderr F I0817 17:50:45.945030       1 controllermanager.go:574] Started "ephemeral-volume"
2021-08-17T17:50:45.945512Z stderr F I0817 17:50:45.945372       1 controller.go:170] Starting ephemeral volume controller
2021-08-17T17:50:45.9455263Z stderr F I0817 17:50:45.945410       1 shared_informer.go:240] Waiting for caches to sync for ephemeral
2021-08-17T17:50:46.0909779Z stderr F I0817 17:50:46.090714       1 controllermanager.go:574] Started "endpointslice"
2021-08-17T17:50:46.0910074Z stderr F I0817 17:50:46.090844       1 endpointslice_controller.go:256] Starting endpoint slice controller
2021-08-17T17:50:46.0910454Z stderr F I0817 17:50:46.090866       1 shared_informer.go:240] Waiting for caches to sync for endpoint_slice
2021-08-17T17:50:46.3399183Z stderr F I0817 17:50:46.339666       1 garbagecollector.go:142] Starting garbage collector controller
2021-08-17T17:50:46.3399506Z stderr F I0817 17:50:46.339709       1 shared_informer.go:240] Waiting for caches to sync for garbage collector
2021-08-17T17:50:46.3399662Z stderr F I0817 17:50:46.339666       1 controllermanager.go:574] Started "garbagecollector"
2021-08-17T17:50:46.3399935Z stderr F I0817 17:50:46.339804       1 graph_builder.go:289] GraphBuilder running
2021-08-17T17:50:46.5941663Z stderr F I0817 17:50:46.593961       1 controllermanager.go:574] Started "job"
2021-08-17T17:50:46.5942003Z stderr F I0817 17:50:46.594063       1 job_controller.go:150] Starting job controller
2021-08-17T17:50:46.5943446Z stderr F I0817 17:50:46.594078       1 shared_informer.go:240] Waiting for caches to sync for job
2021-08-17T17:50:46.6406722Z stderr F I0817 17:50:46.640076       1 controllermanager.go:574] Started "csrsigning"
2021-08-17T17:50:46.6407009Z stderr F I0817 17:50:46.640191       1 certificate_controller.go:118] Starting certificate controller "csrsigning-legacy-unknown"
2021-08-17T17:50:46.6407188Z stderr F I0817 17:50:46.640208       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-legacy-unknown
2021-08-17T17:50:46.6408033Z stderr F I0817 17:50:46.640696       1 certificate_controller.go:118] Starting certificate controller "csrsigning-kubelet-serving"
2021-08-17T17:50:46.640822Z stderr F I0817 17:50:46.640730       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kubelet-serving
2021-08-17T17:50:46.6410567Z stderr F I0817 17:50:46.640852       1 certificate_controller.go:118] Starting certificate controller "csrsigning-kubelet-client"
2021-08-17T17:50:46.6410757Z stderr F I0817 17:50:46.640899       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kubelet-client
2021-08-17T17:50:46.6410898Z stderr F I0817 17:50:46.640938       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
2021-08-17T17:50:46.6410998Z stderr F I0817 17:50:46.640947       1 certificate_controller.go:118] Starting certificate controller "csrsigning-kube-apiserver-client"
2021-08-17T17:50:46.6411098Z stderr F I0817 17:50:46.640992       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kube-apiserver-client
2021-08-17T17:50:46.6411202Z stderr F I0817 17:50:46.640998       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
2021-08-17T17:50:46.6412802Z stderr F I0817 17:50:46.641124       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
2021-08-17T17:50:46.6413424Z stderr F I0817 17:50:46.641173       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
2021-08-17T17:50:46.7908446Z stderr F I0817 17:50:46.790627       1 controllermanager.go:574] Started "pvc-protection"
2021-08-17T17:50:46.790884Z stderr F I0817 17:50:46.790746       1 pvc_protection_controller.go:110] "Starting PVC protection controller"
2021-08-17T17:50:46.7908986Z stderr F I0817 17:50:46.790792       1 shared_informer.go:240] Waiting for caches to sync for PVC protection
2021-08-17T17:50:46.9443963Z stderr F I0817 17:50:46.944052       1 controllermanager.go:574] Started "endpointslicemirroring"
2021-08-17T17:50:46.9444243Z stderr F I0817 17:50:46.944275       1 endpointslicemirroring_controller.go:211] Starting EndpointSliceMirroring controller
2021-08-17T17:50:46.9445284Z stderr F I0817 17:50:46.944296       1 shared_informer.go:240] Waiting for caches to sync for endpoint_slice_mirroring
2021-08-17T17:50:46.9886894Z stderr F I0817 17:50:46.988463       1 node_lifecycle_controller.go:76] Sending events to api server
2021-08-17T17:50:46.9887175Z stderr F E0817 17:50:46.988520       1 core.go:231] failed to start cloud node lifecycle controller: no cloud provider provided
2021-08-17T17:50:46.988734Z stderr F W0817 17:50:46.988535       1 controllermanager.go:566] Skipping "cloud-node-lifecycle"
2021-08-17T17:50:47.1416574Z stderr F I0817 17:50:47.140947       1 controllermanager.go:574] Started "cronjob"
2021-08-17T17:50:47.1416886Z stderr F I0817 17:50:47.141037       1 cronjob_controllerv2.go:125] Starting cronjob controller v2
2021-08-17T17:50:47.1416975Z stderr F I0817 17:50:47.141051       1 shared_informer.go:240] Waiting for caches to sync for cronjob
2021-08-17T17:50:47.2905426Z stderr F I0817 17:50:47.290351       1 controllermanager.go:574] Started "podgc"
2021-08-17T17:50:47.2905671Z stderr F I0817 17:50:47.290443       1 gc_controller.go:89] Starting GC controller
2021-08-17T17:50:47.290595Z stderr F I0817 17:50:47.290456       1 shared_informer.go:240] Waiting for caches to sync for GC
2021-08-17T17:50:47.4408006Z stderr F I0817 17:50:47.440613       1 controllermanager.go:574] Started "replicaset"
2021-08-17T17:50:47.4408324Z stderr F I0817 17:50:47.440729       1 replica_set.go:182] Starting replicaset controller
2021-08-17T17:50:47.4408551Z stderr F I0817 17:50:47.440749       1 shared_informer.go:240] Waiting for caches to sync for ReplicaSet
2021-08-17T17:50:47.4901264Z stderr F I0817 17:50:47.489936       1 node_ipam_controller.go:91] Sending events to api server.
2021-08-17T17:50:57.5144356Z stderr F I0817 17:50:57.513888       1 range_allocator.go:82] Sending events to api server.
2021-08-17T17:50:57.5145099Z stderr F I0817 17:50:57.514148       1 range_allocator.go:116] No Secondary Service CIDR provided. Skipping filtering out secondary service addresses.
2021-08-17T17:50:57.5147705Z stderr F I0817 17:50:57.514350       1 controllermanager.go:574] Started "nodeipam"
2021-08-17T17:50:57.5149684Z stderr F I0817 17:50:57.514740       1 node_ipam_controller.go:154] Starting ipam controller
2021-08-17T17:50:57.5149907Z stderr F I0817 17:50:57.514858       1 shared_informer.go:240] Waiting for caches to sync for node
2021-08-17T17:50:57.5321197Z stderr F E0817 17:50:57.531905       1 core.go:91] Failed to start service controller: WARNING: no cloud provider provided, services of type LoadBalancer will fail
2021-08-17T17:50:57.5324123Z stderr F W0817 17:50:57.531991       1 controllermanager.go:566] Skipping "service"
2021-08-17T17:50:57.5324342Z stderr F W0817 17:50:57.532306       1 core.go:245] configure-cloud-routes is set, but no cloud provider specified. Will not configure cloud provider routes.
2021-08-17T17:50:57.5326051Z stderr F W0817 17:50:57.532487       1 controllermanager.go:566] Skipping "route"
2021-08-17T17:50:57.5453715Z stderr F I0817 17:50:57.545021       1 controllermanager.go:574] Started "endpoint"
2021-08-17T17:50:57.5458097Z stderr F I0817 17:50:57.545624       1 shared_informer.go:240] Waiting for caches to sync for resource quota
2021-08-17T17:50:57.5458286Z stderr F I0817 17:50:57.545769       1 endpoints_controller.go:189] Starting endpoint controller
2021-08-17T17:50:57.5458948Z stderr F I0817 17:50:57.545792       1 shared_informer.go:240] Waiting for caches to sync for endpoint
2021-08-17T17:50:57.597411Z stderr F I0817 17:50:57.597154       1 shared_informer.go:247] Caches are synced for TTL after finished 
2021-08-17T17:50:57.6003888Z stderr F I0817 17:50:57.598311       1 shared_informer.go:247] Caches are synced for job 
2021-08-17T17:50:57.6024215Z stderr F I0817 17:50:57.601864       1 shared_informer.go:247] Caches are synced for ReplicationController 
2021-08-17T17:50:57.6078537Z stderr F I0817 17:50:57.607645       1 shared_informer.go:240] Waiting for caches to sync for garbage collector
2021-08-17T17:50:57.6134632Z stderr F I0817 17:50:57.613126       1 shared_informer.go:247] Caches are synced for namespace 
2021-08-17T17:50:57.6417782Z stderr F I0817 17:50:57.640908       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-legacy-unknown 
2021-08-17T17:50:57.6418045Z stderr F I0817 17:50:57.641043       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kube-apiserver-client 
2021-08-17T17:50:57.6418222Z stderr F I0817 17:50:57.641180       1 shared_informer.go:247] Caches are synced for cronjob 
2021-08-17T17:50:57.6418393Z stderr F I0817 17:50:57.641280       1 shared_informer.go:247] Caches are synced for bootstrap_signer 
2021-08-17T17:50:57.6418535Z stderr F I0817 17:50:57.641314       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kubelet-client 
2021-08-17T17:50:57.6418783Z stderr F I0817 17:50:57.641329       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kubelet-serving 
2021-08-17T17:50:57.6418949Z stderr F I0817 17:50:57.641461       1 shared_informer.go:247] Caches are synced for deployment 
2021-08-17T17:50:57.6421617Z stderr F I0817 17:50:57.641983       1 shared_informer.go:247] Caches are synced for ReplicaSet 
2021-08-17T17:50:57.6442825Z stderr F I0817 17:50:57.642754       1 shared_informer.go:247] Caches are synced for PV protection 
2021-08-17T17:50:57.6443053Z stderr F I0817 17:50:57.643318       1 shared_informer.go:247] Caches are synced for HPA 
2021-08-17T17:50:57.6443184Z stderr F I0817 17:50:57.643380       1 shared_informer.go:247] Caches are synced for service account 
2021-08-17T17:50:57.6447136Z stderr F I0817 17:50:57.644572       1 shared_informer.go:247] Caches are synced for endpoint_slice_mirroring 
2021-08-17T17:50:57.6451175Z stderr F I0817 17:50:57.644980       1 shared_informer.go:247] Caches are synced for ClusterRoleAggregator 
2021-08-17T17:50:57.6465036Z stderr F I0817 17:50:57.646158       1 shared_informer.go:247] Caches are synced for endpoint 
2021-08-17T17:50:57.6599528Z stderr F I0817 17:50:57.659682       1 shared_informer.go:247] Caches are synced for certificate-csrapproving 
2021-08-17T17:50:57.6681396Z stderr F I0817 17:50:57.667012       1 shared_informer.go:247] Caches are synced for crt configmap 
2021-08-17T17:50:57.6786747Z stderr F I0817 17:50:57.678159       1 event.go:291] "Event occurred" object="local-path-storage/local-path-provisioner" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set local-path-provisioner-547f784dff to 1"
2021-08-17T17:50:57.6888457Z stderr F I0817 17:50:57.688465       1 event.go:291] "Event occurred" object="kube-system/coredns" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-558bd4d5db to 2"
2021-08-17T17:50:57.747852Z stderr F I0817 17:50:57.747294       1 shared_informer.go:247] Caches are synced for ephemeral 
2021-08-17T17:50:57.7703232Z stderr F I0817 17:50:57.770054       1 event.go:291] "Event occurred" object="local-path-storage/local-path-provisioner-547f784dff" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: local-path-provisioner-547f784dff-fpkm8"
2021-08-17T17:50:57.7706778Z stderr F I0817 17:50:57.770428       1 event.go:291] "Event occurred" object="kube-system/coredns-558bd4d5db" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-558bd4d5db-dsndw"
2021-08-17T17:50:57.7816851Z stderr F I0817 17:50:57.781454       1 event.go:291] "Event occurred" object="kube-system/coredns-558bd4d5db" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-558bd4d5db-bjv9d"
2021-08-17T17:50:57.7904393Z stderr F I0817 17:50:57.790195       1 shared_informer.go:247] Caches are synced for expand 
2021-08-17T17:50:57.7966042Z stderr F I0817 17:50:57.796388       1 shared_informer.go:247] Caches are synced for PVC protection 
2021-08-17T17:50:57.8036541Z stderr F W0817 17:50:57.803443       1 actual_state_of_world.go:534] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="config-control-plane" does not exist
2021-08-17T17:50:57.8157917Z stderr F I0817 17:50:57.815250       1 shared_informer.go:247] Caches are synced for node 
2021-08-17T17:50:57.8158143Z stderr F I0817 17:50:57.815299       1 range_allocator.go:172] Starting range CIDR allocator
2021-08-17T17:50:57.8158343Z stderr F I0817 17:50:57.815314       1 shared_informer.go:240] Waiting for caches to sync for cidrallocator
2021-08-17T17:50:57.8158452Z stderr F I0817 17:50:57.815325       1 shared_informer.go:247] Caches are synced for cidrallocator 
2021-08-17T17:50:57.8218422Z stderr F I0817 17:50:57.821596       1 shared_informer.go:247] Caches are synced for daemon sets 
2021-08-17T17:50:57.8244067Z stderr F I0817 17:50:57.822103       1 range_allocator.go:373] Set node config-control-plane PodCIDR to [10.20.0.0/24]
2021-08-17T17:50:57.8429567Z stderr F I0817 17:50:57.842697       1 shared_informer.go:247] Caches are synced for persistent volume 
2021-08-17T17:50:57.8456023Z stderr F I0817 17:50:57.845381       1 shared_informer.go:247] Caches are synced for attach detach 
2021-08-17T17:50:57.8499824Z stderr F I0817 17:50:57.849784       1 event.go:291] "Event occurred" object="kube-system/kube-proxy" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-qk46c"
2021-08-17T17:50:57.8585041Z stderr F I0817 17:50:57.858332       1 shared_informer.go:247] Caches are synced for disruption 
2021-08-17T17:50:57.8585342Z stderr F I0817 17:50:57.858429       1 disruption.go:371] Sending events to api server.
2021-08-17T17:50:57.8671641Z stderr F I0817 17:50:57.866349       1 event.go:291] "Event occurred" object="kube-system/kindnet" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kindnet-z8xnr"
2021-08-17T17:50:57.8747856Z stderr F I0817 17:50:57.872796       1 shared_informer.go:247] Caches are synced for TTL 
2021-08-17T17:50:57.8921495Z stderr F I0817 17:50:57.891635       1 shared_informer.go:247] Caches are synced for GC 
2021-08-17T17:50:57.8921783Z stderr F I0817 17:50:57.891869       1 shared_informer.go:247] Caches are synced for stateful set 
2021-08-17T17:50:57.8929571Z stderr F I0817 17:50:57.892819       1 shared_informer.go:247] Caches are synced for endpoint_slice 
2021-08-17T17:50:57.8974324Z stderr F I0817 17:50:57.893159       1 shared_informer.go:247] Caches are synced for taint 
2021-08-17T17:50:57.8974648Z stderr F I0817 17:50:57.893353       1 node_lifecycle_controller.go:1398] Initializing eviction metric for zone: 
2021-08-17T17:50:57.8974791Z stderr F W0817 17:50:57.893451       1 node_lifecycle_controller.go:1013] Missing timestamp for Node config-control-plane. Assuming now as a timestamp.
2021-08-17T17:50:57.8974881Z stderr F I0817 17:50:57.893544       1 taint_manager.go:187] "Starting NoExecuteTaintManager"
2021-08-17T17:50:57.8975073Z stderr F I0817 17:50:57.893592       1 node_lifecycle_controller.go:1164] Controller detected that all Nodes are not-Ready. Entering master disruption mode.
2021-08-17T17:50:57.8975224Z stderr F I0817 17:50:57.894163       1 event.go:291] "Event occurred" object="config-control-plane" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node config-control-plane event: Registered Node config-control-plane in Controller"
2021-08-17T17:50:57.90269Z stderr F I0817 17:50:57.902452       1 event.go:291] "Event occurred" object="kube-system/kube-scheduler-config-control-plane" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
2021-08-17T17:50:57.9076273Z stderr F E0817 17:50:57.907208       1 daemon_controller.go:320] kube-system/kindnet failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kindnet", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"2e9e85e7-b95a-4e0f-bf65-562f7aef34bf", ResourceVersion:"330", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63764819445, loc:(*time.Location)(0x72f5420)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"kindnet", "k8s-app":"kindnet", "tier":"node"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"kubectl-create", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc0016110e0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0016110f8)}}}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc0016150e0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"kindnet", "k8s-app":"kindnet", "tier":"node"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"cni-cfg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001611110), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}, v1.Volume{Name:"xtables-lock", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001611128), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}, v1.Volume{Name:"lib-modules", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001611140), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"kindnet-cni", Image:"docker.io/kindest/kindnetd:v20210326-1e038dc5", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"HOST_IP", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001615100)}, v1.EnvVar{Name:"POD_IP", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001615140)}, v1.EnvVar{Name:"POD_SUBNET", Value:"10.20.0.0/16", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"CONTROL_PLANE_ENDPOINT", Value:"config-control-plane:6443", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"cni-cfg", ReadOnly:false, MountPath:"/etc/cni/net.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"xtables-lock", ReadOnly:false, MountPath:"/run/xtables.lock", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"lib-modules", ReadOnly:true, MountPath:"/lib/modules", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc001630ea0), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00160f218), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"kindnet", DeprecatedServiceAccount:"kindnet", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0001b6fc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc001609f00)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc00160f248)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:0, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "kindnet": the object has been modified; please apply your changes to the latest version and try again
2021-08-17T17:50:57.911126Z stderr F I0817 17:50:57.910928       1 shared_informer.go:247] Caches are synced for resource quota 
2021-08-17T17:50:57.9464784Z stderr F I0817 17:50:57.946278       1 shared_informer.go:247] Caches are synced for resource quota 
2021-08-17T17:50:58.3116705Z stderr F I0817 17:50:58.309358       1 shared_informer.go:247] Caches are synced for garbage collector 
2021-08-17T17:50:58.341999Z stderr F I0817 17:50:58.340096       1 shared_informer.go:247] Caches are synced for garbage collector 
2021-08-17T17:50:58.342035Z stderr F I0817 17:50:58.340139       1 garbagecollector.go:151] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
2021-08-17T17:51:16.4681195Z stderr F I0817 17:51:16.467884       1 event.go:291] "Event occurred" object="kube-system/metrics-server" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set metrics-server-99b5b5fc6 to 1"
2021-08-17T17:51:16.4846214Z stderr F I0817 17:51:16.483224       1 event.go:291] "Event occurred" object="kube-system/metrics-server-99b5b5fc6" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: metrics-server-99b5b5fc6-89vcp"
2021-08-17T17:51:17.8632853Z stderr F I0817 17:51:17.863007       1 node_lifecycle_controller.go:1191] Controller detected that some Nodes are Ready. Exiting master disruption mode.
2021-08-17T17:51:18.4399351Z stderr F I0817 17:51:18.439373       1 event.go:291] "Event occurred" object="metallb-system/speaker" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: speaker-qzsn6"
2021-08-17T17:51:18.4500372Z stderr F I0817 17:51:18.449843       1 event.go:291] "Event occurred" object="metallb-system/controller" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set controller-fb659dc8 to 1"
2021-08-17T17:51:18.462362Z stderr F I0817 17:51:18.461087       1 event.go:291] "Event occurred" object="metallb-system/controller-fb659dc8" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: controller-fb659dc8-sqvlg"
2021-08-17T17:51:18.509072Z stderr F E0817 17:51:18.507017       1 daemon_controller.go:320] metallb-system/speaker failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"speaker", GenerateName:"", Namespace:"metallb-system", SelfLink:"", UID:"15f418fc-1c20-4242-b9ea-e2ea03c12d12", ResourceVersion:"585", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63764819478, loc:(*time.Location)(0x72f5420)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"metallb", "component":"speaker"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"app\":\"metallb\",\"component\":\"speaker\"},\"name\":\"speaker\",\"namespace\":\"metallb-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"app\":\"metallb\",\"component\":\"speaker\"}},\"template\":{\"metadata\":{\"annotations\":{\"prometheus.io/port\":\"7472\",\"prometheus.io/scrape\":\"true\"},\"labels\":{\"app\":\"metallb\",\"component\":\"speaker\"}},\"spec\":{\"containers\":[{\"args\":[\"--port=7472\",\"--config=config\"],\"env\":[{\"name\":\"METALLB_NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"METALLB_HOST\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"status.hostIP\"}}},{\"name\":\"METALLB_ML_BIND_ADDR\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"status.podIP\"}}},{\"name\":\"METALLB_ML_LABELS\",\"value\":\"app=metallb,component=speaker\"},{\"name\":\"METALLB_ML_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}},{\"name\":\"METALLB_ML_SECRET_KEY\",\"valueFrom\":{\"secretKeyRef\":{\"key\":\"secretkey\",\"name\":\"memberlist\"}}}],\"image\":\"metallb/speaker:v0.9.3\",\"imagePullPolicy\":\"Always\",\"name\":\"speaker\",\"ports\":[{\"containerPort\":7472,\"name\":\"monitoring\"}],\"resources\":{\"limits\":{\"cpu\":\"100m\",\"memory\":\"100Mi\"}},\"securityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"add\":[\"NET_ADMIN\",\"NET_RAW\",\"SYS_ADMIN\"],\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true}}],\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"serviceAccountName\":\"speaker\",\"terminationGracePeriodSeconds\":2,\"tolerations\":[{\"effect\":\"NoSchedule\",\"key\":\"node-role.kubernetes.io/master\"}]}}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"kubectl-client-side-apply", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc0008afed8), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0008afef0)}}}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc001b16e60), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"metallb", "component":"speaker"}, Annotations:map[string]string{"prometheus.io/port":"7472", "prometheus.io/scrape":"true"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume(nil), InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"speaker", Image:"metallb/speaker:v0.9.3", Command:[]string(nil), Args:[]string{"--port=7472", "--config=config"}, WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"monitoring", HostPort:7472, ContainerPort:7472, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"METALLB_NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001b16ea0)}, v1.EnvVar{Name:"METALLB_HOST", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001b16ee0)}, v1.EnvVar{Name:"METALLB_ML_BIND_ADDR", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001b16f20)}, v1.EnvVar{Name:"METALLB_ML_LABELS", Value:"app=metallb,component=speaker", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"METALLB_ML_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001b16f60)}, v1.EnvVar{Name:"METALLB_ML_SECRET_KEY", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001b16fa0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:104857600, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100Mi", Format:"BinarySI"}}, Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(0xc001ec1020), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002521f38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"speaker", DeprecatedServiceAccount:"speaker", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0002b1730), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node-role.kubernetes.io/master", Operator:"", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc00200c000)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc002521f88)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:0, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "speaker": the object has been modified; please apply your changes to the latest version and try again
2021-08-17T17:51:18.5637965Z stderr F E0817 17:51:18.560157       1 daemon_controller.go:320] metallb-system/speaker failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"speaker", GenerateName:"", Namespace:"metallb-system", SelfLink:"", UID:"15f418fc-1c20-4242-b9ea-e2ea03c12d12", ResourceVersion:"590", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63764819478, loc:(*time.Location)(0x72f5420)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"metallb", "component":"speaker"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"app\":\"metallb\",\"component\":\"speaker\"},\"name\":\"speaker\",\"namespace\":\"metallb-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"app\":\"metallb\",\"component\":\"speaker\"}},\"template\":{\"metadata\":{\"annotations\":{\"prometheus.io/port\":\"7472\",\"prometheus.io/scrape\":\"true\"},\"labels\":{\"app\":\"metallb\",\"component\":\"speaker\"}},\"spec\":{\"containers\":[{\"args\":[\"--port=7472\",\"--config=config\"],\"env\":[{\"name\":\"METALLB_NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"METALLB_HOST\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"status.hostIP\"}}},{\"name\":\"METALLB_ML_BIND_ADDR\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"status.podIP\"}}},{\"name\":\"METALLB_ML_LABELS\",\"value\":\"app=metallb,component=speaker\"},{\"name\":\"METALLB_ML_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}},{\"name\":\"METALLB_ML_SECRET_KEY\",\"valueFrom\":{\"secretKeyRef\":{\"key\":\"secretkey\",\"name\":\"memberlist\"}}}],\"image\":\"metallb/speaker:v0.9.3\",\"imagePullPolicy\":\"Always\",\"name\":\"speaker\",\"ports\":[{\"containerPort\":7472,\"name\":\"monitoring\"}],\"resources\":{\"limits\":{\"cpu\":\"100m\",\"memory\":\"100Mi\"}},\"securityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"add\":[\"NET_ADMIN\",\"NET_RAW\",\"SYS_ADMIN\"],\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true}}],\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"serviceAccountName\":\"speaker\",\"terminationGracePeriodSeconds\":2,\"tolerations\":[{\"effect\":\"NoSchedule\",\"key\":\"node-role.kubernetes.io/master\"}]}}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc0005276e0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0005276f8)}, v1.ManagedFieldsEntry{Manager:"kubectl-client-side-apply", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc000527710), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000527740)}}}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc00191fa00), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"metallb", "component":"speaker"}, Annotations:map[string]string{"prometheus.io/port":"7472", "prometheus.io/scrape":"true"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume(nil), InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"speaker", Image:"metallb/speaker:v0.9.3", Command:[]string(nil), Args:[]string{"--port=7472", "--config=config"}, WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"monitoring", HostPort:7472, ContainerPort:7472, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"METALLB_NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00191fa40)}, v1.EnvVar{Name:"METALLB_HOST", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00191fa80)}, v1.EnvVar{Name:"METALLB_ML_BIND_ADDR", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00191fac0)}, v1.EnvVar{Name:"METALLB_ML_LABELS", Value:"app=metallb,component=speaker", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"METALLB_ML_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00191fb00)}, v1.EnvVar{Name:"METALLB_ML_SECRET_KEY", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00191fba0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:104857600, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100Mi", Format:"BinarySI"}}, Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(0xc0012fc8a0), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0014000d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"speaker", DeprecatedServiceAccount:"speaker", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000766770), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node-role.kubernetes.io/master", Operator:"", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc001edc750)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc001400108)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:1, NumberReady:0, ObservedGeneration:1, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:1, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "speaker": the object has been modified; please apply your changes to the latest version and try again
