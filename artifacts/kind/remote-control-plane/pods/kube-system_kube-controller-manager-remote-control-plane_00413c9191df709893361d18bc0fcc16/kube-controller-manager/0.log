2021-08-17T17:50:32.3922244Z stderr F Flag --port has been deprecated, see --secure-port instead.
2021-08-17T17:50:33.3548764Z stderr F I0817 17:50:33.350843       1 serving.go:347] Generated self-signed cert in-memory
2021-08-17T17:50:34.1367968Z stderr F I0817 17:50:34.136670       1 controllermanager.go:175] Version: v1.21.1
2021-08-17T17:50:34.1393668Z stderr F I0817 17:50:34.137866       1 dynamic_cafile_content.go:167] Starting request-header::/etc/kubernetes/pki/front-proxy-ca.crt
2021-08-17T17:50:34.1393891Z stderr F I0817 17:50:34.137965       1 dynamic_cafile_content.go:167] Starting client-ca-bundle::/etc/kubernetes/pki/ca.crt
2021-08-17T17:50:34.1394082Z stderr F I0817 17:50:34.137997       1 secure_serving.go:197] Serving securely on 127.0.0.1:10257
2021-08-17T17:50:34.1394213Z stderr F I0817 17:50:34.138213       1 tlsconfig.go:240] Starting DynamicServingCertificateController
2021-08-17T17:50:34.1394385Z stderr F I0817 17:50:34.138276       1 leaderelection.go:243] attempting to acquire leader lease kube-system/kube-controller-manager...
2021-08-17T17:50:39.1391727Z stderr F E0817 17:50:39.138893       1 leaderelection.go:325] error retrieving resource lock kube-system/kube-controller-manager: Get "https://172.18.0.2:6443/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-controller-manager?timeout=5s": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
2021-08-17T17:50:42.6459702Z stderr F E0817 17:50:42.645817       1 leaderelection.go:325] error retrieving resource lock kube-system/kube-controller-manager: leases.coordination.k8s.io "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-system"
2021-08-17T17:50:46.6803262Z stderr F I0817 17:50:46.679930       1 leaderelection.go:253] successfully acquired lease kube-system/kube-controller-manager
2021-08-17T17:50:46.6809514Z stderr F I0817 17:50:46.680776       1 event.go:291] "Event occurred" object="kube-system/kube-controller-manager" kind="Lease" apiVersion="coordination.k8s.io/v1" type="Normal" reason="LeaderElection" message="remote-control-plane_02413382-2ef2-4a1c-8a97-eb948db17846 became leader"
2021-08-17T17:50:47.2423768Z stderr F I0817 17:50:47.242171       1 shared_informer.go:240] Waiting for caches to sync for tokens
2021-08-17T17:50:47.2726644Z stderr F I0817 17:50:47.271870       1 garbagecollector.go:142] Starting garbage collector controller
2021-08-17T17:50:47.2727285Z stderr F I0817 17:50:47.272017       1 shared_informer.go:240] Waiting for caches to sync for garbage collector
2021-08-17T17:50:47.2727436Z stderr F I0817 17:50:47.272074       1 graph_builder.go:289] GraphBuilder running
2021-08-17T17:50:47.2730301Z stderr F I0817 17:50:47.272788       1 controllermanager.go:574] Started "garbagecollector"
2021-08-17T17:50:47.2892939Z stderr F I0817 17:50:47.288832       1 controllermanager.go:574] Started "attachdetach"
2021-08-17T17:50:47.2899144Z stderr F I0817 17:50:47.289061       1 attach_detach_controller.go:327] Starting attach detach controller
2021-08-17T17:50:47.2899354Z stderr F I0817 17:50:47.289094       1 shared_informer.go:240] Waiting for caches to sync for attach detach
2021-08-17T17:50:47.3135109Z stderr F I0817 17:50:47.313342       1 controllermanager.go:574] Started "persistentvolume-expander"
2021-08-17T17:50:47.3137177Z stderr F I0817 17:50:47.313547       1 expand_controller.go:327] Starting expand controller
2021-08-17T17:50:47.3138023Z stderr F I0817 17:50:47.313585       1 shared_informer.go:240] Waiting for caches to sync for expand
2021-08-17T17:50:47.3432441Z stderr F I0817 17:50:47.342908       1 shared_informer.go:247] Caches are synced for tokens 
2021-08-17T17:50:47.358813Z stderr F I0817 17:50:47.357360       1 controllermanager.go:574] Started "endpointslice"
2021-08-17T17:50:47.3588416Z stderr F I0817 17:50:47.357582       1 endpointslice_controller.go:256] Starting endpoint slice controller
2021-08-17T17:50:47.3588661Z stderr F I0817 17:50:47.357615       1 shared_informer.go:240] Waiting for caches to sync for endpoint_slice
2021-08-17T17:50:47.3864506Z stderr F I0817 17:50:47.386074       1 controllermanager.go:574] Started "bootstrapsigner"
2021-08-17T17:50:47.3864841Z stderr F I0817 17:50:47.386247       1 shared_informer.go:240] Waiting for caches to sync for bootstrap_signer
2021-08-17T17:50:47.410006Z stderr F I0817 17:50:47.409644       1 controllermanager.go:574] Started "tokencleaner"
2021-08-17T17:50:47.4100342Z stderr F I0817 17:50:47.409764       1 tokencleaner.go:118] Starting token cleaner controller
2021-08-17T17:50:47.4100682Z stderr F I0817 17:50:47.409781       1 shared_informer.go:240] Waiting for caches to sync for token_cleaner
2021-08-17T17:50:47.4100817Z stderr F I0817 17:50:47.409792       1 shared_informer.go:247] Caches are synced for token_cleaner 
2021-08-17T17:50:47.4368266Z stderr F I0817 17:50:47.434849       1 node_lifecycle_controller.go:76] Sending events to api server
2021-08-17T17:50:47.4369725Z stderr F E0817 17:50:47.435013       1 core.go:231] failed to start cloud node lifecycle controller: no cloud provider provided
2021-08-17T17:50:47.4369866Z stderr F W0817 17:50:47.436218       1 controllermanager.go:566] Skipping "cloud-node-lifecycle"
2021-08-17T17:50:47.4548164Z stderr F I0817 17:50:47.454105       1 controllermanager.go:574] Started "ephemeral-volume"
2021-08-17T17:50:47.4550977Z stderr F I0817 17:50:47.454957       1 controller.go:170] Starting ephemeral volume controller
2021-08-17T17:50:47.4551643Z stderr F I0817 17:50:47.454995       1 shared_informer.go:240] Waiting for caches to sync for ephemeral
2021-08-17T17:50:47.4746399Z stderr F I0817 17:50:47.474527       1 controllermanager.go:574] Started "endpointslicemirroring"
2021-08-17T17:50:47.4753559Z stderr F I0817 17:50:47.474621       1 endpointslicemirroring_controller.go:211] Starting EndpointSliceMirroring controller
2021-08-17T17:50:47.4753808Z stderr F I0817 17:50:47.474734       1 shared_informer.go:240] Waiting for caches to sync for endpoint_slice_mirroring
2021-08-17T17:50:47.5965504Z stderr F I0817 17:50:47.596293       1 controllermanager.go:574] Started "namespace"
2021-08-17T17:50:47.5968764Z stderr F I0817 17:50:47.596673       1 namespace_controller.go:200] Starting namespace controller
2021-08-17T17:50:47.596922Z stderr F I0817 17:50:47.596794       1 shared_informer.go:240] Waiting for caches to sync for namespace
2021-08-17T17:50:47.7058912Z stderr F I0817 17:50:47.705591       1 controllermanager.go:574] Started "persistentvolume-binder"
2021-08-17T17:50:47.7059208Z stderr F I0817 17:50:47.705688       1 pv_controller_base.go:308] Starting persistent volume controller
2021-08-17T17:50:47.705936Z stderr F I0817 17:50:47.705703       1 shared_informer.go:240] Waiting for caches to sync for persistent volume
2021-08-17T17:50:47.8487705Z stderr F I0817 17:50:47.848552       1 controllermanager.go:574] Started "podgc"
2021-08-17T17:50:47.8488007Z stderr F I0817 17:50:47.848600       1 gc_controller.go:89] Starting GC controller
2021-08-17T17:50:47.8488087Z stderr F I0817 17:50:47.848623       1 shared_informer.go:240] Waiting for caches to sync for GC
2021-08-17T17:50:48.1507724Z stderr F I0817 17:50:48.150542       1 controllermanager.go:574] Started "horizontalpodautoscaling"
2021-08-17T17:50:48.1510642Z stderr F I0817 17:50:48.150635       1 horizontal.go:169] Starting HPA controller
2021-08-17T17:50:48.1510896Z stderr F I0817 17:50:48.150926       1 shared_informer.go:240] Waiting for caches to sync for HPA
2021-08-17T17:50:48.3005068Z stderr F E0817 17:50:48.300160       1 core.go:91] Failed to start service controller: WARNING: no cloud provider provided, services of type LoadBalancer will fail
2021-08-17T17:50:48.3006143Z stderr F W0817 17:50:48.300189       1 controllermanager.go:566] Skipping "service"
2021-08-17T17:50:48.4470367Z stderr F I0817 17:50:48.446873       1 controllermanager.go:574] Started "pvc-protection"
2021-08-17T17:50:48.4473479Z stderr F I0817 17:50:48.447132       1 pvc_protection_controller.go:110] "Starting PVC protection controller"
2021-08-17T17:50:48.4474755Z stderr F I0817 17:50:48.447342       1 shared_informer.go:240] Waiting for caches to sync for PVC protection
2021-08-17T17:50:48.6036462Z stderr F I0817 17:50:48.603393       1 controllermanager.go:574] Started "root-ca-cert-publisher"
2021-08-17T17:50:48.6037147Z stderr F I0817 17:50:48.603483       1 publisher.go:102] Starting root CA certificate configmap publisher
2021-08-17T17:50:48.6037331Z stderr F I0817 17:50:48.603500       1 shared_informer.go:240] Waiting for caches to sync for crt configmap
2021-08-17T17:50:48.7523709Z stderr F I0817 17:50:48.752085       1 controllermanager.go:574] Started "replicationcontroller"
2021-08-17T17:50:48.7524138Z stderr F I0817 17:50:48.752258       1 replica_set.go:182] Starting replicationcontroller controller
2021-08-17T17:50:48.7524306Z stderr F I0817 17:50:48.752274       1 shared_informer.go:240] Waiting for caches to sync for ReplicationController
2021-08-17T17:50:48.8993651Z stderr F I0817 17:50:48.899107       1 controllermanager.go:574] Started "cronjob"
2021-08-17T17:50:48.8995496Z stderr F I0817 17:50:48.899149       1 cronjob_controllerv2.go:125] Starting cronjob controller v2
2021-08-17T17:50:48.8996052Z stderr F I0817 17:50:48.899558       1 shared_informer.go:240] Waiting for caches to sync for cronjob
2021-08-17T17:50:49.0553201Z stderr F I0817 17:50:49.054844       1 controllermanager.go:574] Started "job"
2021-08-17T17:50:49.0553592Z stderr F I0817 17:50:49.054996       1 job_controller.go:150] Starting job controller
2021-08-17T17:50:49.0553699Z stderr F I0817 17:50:49.055021       1 shared_informer.go:240] Waiting for caches to sync for job
2021-08-17T17:50:49.1984236Z stderr F I0817 17:50:49.198176       1 controllermanager.go:574] Started "deployment"
2021-08-17T17:50:49.1984579Z stderr F I0817 17:50:49.198328       1 deployment_controller.go:153] "Starting controller" controller="deployment"
2021-08-17T17:50:49.1984873Z stderr F I0817 17:50:49.198361       1 shared_informer.go:240] Waiting for caches to sync for deployment
2021-08-17T17:50:49.3474997Z stderr F I0817 17:50:49.347292       1 controllermanager.go:574] Started "csrapproving"
2021-08-17T17:50:49.3475955Z stderr F I0817 17:50:49.347388       1 certificate_controller.go:118] Starting certificate controller "csrapproving"
2021-08-17T17:50:49.3476132Z stderr F I0817 17:50:49.347402       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrapproving
2021-08-17T17:50:49.3985477Z stderr F I0817 17:50:49.398206       1 controllermanager.go:574] Started "csrcleaner"
2021-08-17T17:50:49.3987056Z stderr F I0817 17:50:49.398516       1 cleaner.go:82] Starting CSR cleaner controller
2021-08-17T17:50:49.4474879Z stderr F I0817 17:50:49.447313       1 node_ipam_controller.go:91] Sending events to api server.
2021-08-17T17:50:59.4776597Z stderr F I0817 17:50:59.477400       1 range_allocator.go:82] Sending events to api server.
2021-08-17T17:50:59.4777141Z stderr F I0817 17:50:59.477616       1 range_allocator.go:116] No Secondary Service CIDR provided. Skipping filtering out secondary service addresses.
2021-08-17T17:50:59.4777525Z stderr F I0817 17:50:59.477680       1 controllermanager.go:574] Started "nodeipam"
2021-08-17T17:50:59.4780612Z stderr F I0817 17:50:59.477805       1 node_ipam_controller.go:154] Starting ipam controller
2021-08-17T17:50:59.4780903Z stderr F I0817 17:50:59.477871       1 shared_informer.go:240] Waiting for caches to sync for node
2021-08-17T17:50:59.4923094Z stderr F I0817 17:50:59.491852       1 controllermanager.go:574] Started "ttl-after-finished"
2021-08-17T17:50:59.4923421Z stderr F I0817 17:50:59.492047       1 ttlafterfinished_controller.go:109] Starting TTL after finished controller
2021-08-17T17:50:59.4923573Z stderr F I0817 17:50:59.492107       1 shared_informer.go:240] Waiting for caches to sync for TTL after finished
2021-08-17T17:50:59.5639682Z stderr F I0817 17:50:59.563381       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for endpoints
2021-08-17T17:50:59.5639963Z stderr F I0817 17:50:59.563494       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for controllerrevisions.apps
2021-08-17T17:50:59.5640276Z stderr F I0817 17:50:59.563534       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for horizontalpodautoscalers.autoscaling
2021-08-17T17:50:59.5640442Z stderr F I0817 17:50:59.563602       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for roles.rbac.authorization.k8s.io
2021-08-17T17:50:59.5640585Z stderr F I0817 17:50:59.563677       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for deployments.apps
2021-08-17T17:50:59.564068Z stderr F I0817 17:50:59.563730       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for daemonsets.apps
2021-08-17T17:50:59.5640782Z stderr F W0817 17:50:59.563770       1 shared_informer.go:494] resyncPeriod 13h20m35.417247683s is smaller than resyncCheckPeriod 21h31m5.863697508s and the informer has already started. Changing it to 21h31m5.863697508s
2021-08-17T17:50:59.5654576Z stderr F I0817 17:50:59.564177       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for jobs.batch
2021-08-17T17:50:59.565481Z stderr F I0817 17:50:59.564595       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for networkpolicies.networking.k8s.io
2021-08-17T17:50:59.565498Z stderr F I0817 17:50:59.564658       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for limitranges
2021-08-17T17:50:59.5655679Z stderr F I0817 17:50:59.564709       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for ingresses.networking.k8s.io
2021-08-17T17:50:59.565584Z stderr F I0817 17:50:59.564749       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for ingresses.extensions
2021-08-17T17:50:59.5655976Z stderr F I0817 17:50:59.564792       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for csistoragecapacities.storage.k8s.io
2021-08-17T17:50:59.5656072Z stderr F I0817 17:50:59.564832       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for leases.coordination.k8s.io
2021-08-17T17:50:59.5656219Z stderr F I0817 17:50:59.564870       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for endpointslices.discovery.k8s.io
2021-08-17T17:50:59.5656418Z stderr F W0817 17:50:59.564891       1 shared_informer.go:494] resyncPeriod 14h7m32.386294014s is smaller than resyncCheckPeriod 21h31m5.863697508s and the informer has already started. Changing it to 21h31m5.863697508s
2021-08-17T17:50:59.5656574Z stderr F I0817 17:50:59.565077       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for serviceaccounts
2021-08-17T17:50:59.5656714Z stderr F I0817 17:50:59.565113       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for podtemplates
2021-08-17T17:50:59.5656831Z stderr F I0817 17:50:59.565148       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for events.events.k8s.io
2021-08-17T17:50:59.5656939Z stderr F I0817 17:50:59.565176       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for replicasets.apps
2021-08-17T17:50:59.5657119Z stderr F I0817 17:50:59.565254       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for cronjobs.batch
2021-08-17T17:50:59.5657237Z stderr F I0817 17:50:59.565315       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for statefulsets.apps
2021-08-17T17:50:59.5677975Z stderr F I0817 17:50:59.565378       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for poddisruptionbudgets.policy
2021-08-17T17:50:59.5678234Z stderr F I0817 17:50:59.565476       1 resource_quota_monitor.go:229] QuotaMonitor created object count evaluator for rolebindings.rbac.authorization.k8s.io
2021-08-17T17:50:59.5678394Z stderr F I0817 17:50:59.565513       1 controllermanager.go:574] Started "resourcequota"
2021-08-17T17:50:59.5678635Z stderr F I0817 17:50:59.565811       1 resource_quota_controller.go:273] Starting resource quota controller
2021-08-17T17:50:59.5678971Z stderr F I0817 17:50:59.565851       1 shared_informer.go:240] Waiting for caches to sync for resource quota
2021-08-17T17:50:59.5679082Z stderr F I0817 17:50:59.565897       1 resource_quota_monitor.go:304] QuotaMonitor running
2021-08-17T17:50:59.5888529Z stderr F I0817 17:50:59.586745       1 controllermanager.go:574] Started "serviceaccount"
2021-08-17T17:50:59.5888782Z stderr F I0817 17:50:59.586942       1 serviceaccounts_controller.go:117] Starting service account controller
2021-08-17T17:50:59.5888952Z stderr F I0817 17:50:59.586980       1 shared_informer.go:240] Waiting for caches to sync for service account
2021-08-17T17:50:59.6484585Z stderr F I0817 17:50:59.648091       1 controllermanager.go:574] Started "replicaset"
2021-08-17T17:50:59.648491Z stderr F I0817 17:50:59.648416       1 replica_set.go:182] Starting replicaset controller
2021-08-17T17:50:59.6486416Z stderr F I0817 17:50:59.648448       1 shared_informer.go:240] Waiting for caches to sync for ReplicaSet
2021-08-17T17:50:59.6956105Z stderr F I0817 17:50:59.693346       1 controllermanager.go:574] Started "disruption"
2021-08-17T17:50:59.6969669Z stderr F I0817 17:50:59.693554       1 disruption.go:363] Starting disruption controller
2021-08-17T17:50:59.6969841Z stderr F I0817 17:50:59.693584       1 shared_informer.go:240] Waiting for caches to sync for disruption
2021-08-17T17:50:59.7040548Z stderr F I0817 17:50:59.703583       1 certificate_controller.go:118] Starting certificate controller "csrsigning-kubelet-serving"
2021-08-17T17:50:59.7040833Z stderr F I0817 17:50:59.703626       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kubelet-serving
2021-08-17T17:50:59.7054916Z stderr F I0817 17:50:59.703671       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
2021-08-17T17:50:59.705506Z stderr F I0817 17:50:59.703771       1 certificate_controller.go:118] Starting certificate controller "csrsigning-kubelet-client"
2021-08-17T17:50:59.7055393Z stderr F I0817 17:50:59.703792       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kubelet-client
2021-08-17T17:50:59.7090891Z stderr F I0817 17:50:59.704019       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
2021-08-17T17:50:59.7091163Z stderr F I0817 17:50:59.705015       1 certificate_controller.go:118] Starting certificate controller "csrsigning-kube-apiserver-client"
2021-08-17T17:50:59.7091372Z stderr F I0817 17:50:59.705035       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-kube-apiserver-client
2021-08-17T17:50:59.7091496Z stderr F I0817 17:50:59.706487       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
2021-08-17T17:50:59.7091594Z stderr F I0817 17:50:59.706735       1 controllermanager.go:574] Started "csrsigning"
2021-08-17T17:50:59.7091744Z stderr F I0817 17:50:59.706936       1 certificate_controller.go:118] Starting certificate controller "csrsigning-legacy-unknown"
2021-08-17T17:50:59.7091886Z stderr F I0817 17:50:59.706948       1 shared_informer.go:240] Waiting for caches to sync for certificate-csrsigning-legacy-unknown
2021-08-17T17:50:59.7091974Z stderr F I0817 17:50:59.707010       1 dynamic_serving_content.go:130] Starting csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key
2021-08-17T17:50:59.7458854Z stderr F I0817 17:50:59.745651       1 controllermanager.go:574] Started "ttl"
2021-08-17T17:50:59.7459136Z stderr F I0817 17:50:59.745785       1 ttl_controller.go:121] Starting TTL controller
2021-08-17T17:50:59.7459802Z stderr F I0817 17:50:59.745799       1 shared_informer.go:240] Waiting for caches to sync for TTL
2021-08-17T17:50:59.7532299Z stderr F I0817 17:50:59.752968       1 node_lifecycle_controller.go:377] Sending events to api server.
2021-08-17T17:50:59.7533707Z stderr F I0817 17:50:59.753160       1 taint_manager.go:163] "Sending events to api server"
2021-08-17T17:50:59.7537724Z stderr F I0817 17:50:59.753628       1 node_lifecycle_controller.go:505] Controller will reconcile labels.
2021-08-17T17:50:59.7537949Z stderr F I0817 17:50:59.753678       1 controllermanager.go:574] Started "nodelifecycle"
2021-08-17T17:50:59.7538227Z stderr F W0817 17:50:59.753704       1 core.go:245] configure-cloud-routes is set, but no cloud provider specified. Will not configure cloud provider routes.
2021-08-17T17:50:59.7538373Z stderr F W0817 17:50:59.753720       1 controllermanager.go:566] Skipping "route"
2021-08-17T17:50:59.7542811Z stderr F I0817 17:50:59.754054       1 node_lifecycle_controller.go:539] Starting node controller
2021-08-17T17:50:59.7543126Z stderr F I0817 17:50:59.754085       1 shared_informer.go:240] Waiting for caches to sync for taint
2021-08-17T17:50:59.7731157Z stderr F I0817 17:50:59.772926       1 controllermanager.go:574] Started "endpoint"
2021-08-17T17:50:59.7736952Z stderr F I0817 17:50:59.773518       1 endpoints_controller.go:189] Starting endpoint controller
2021-08-17T17:50:59.7737152Z stderr F I0817 17:50:59.773573       1 shared_informer.go:240] Waiting for caches to sync for endpoint
2021-08-17T17:50:59.7879453Z stderr F I0817 17:50:59.787758       1 controllermanager.go:574] Started "pv-protection"
2021-08-17T17:50:59.788057Z stderr F I0817 17:50:59.787959       1 pv_protection_controller.go:83] Starting PV protection controller
2021-08-17T17:50:59.7880745Z stderr F I0817 17:50:59.787988       1 shared_informer.go:240] Waiting for caches to sync for PV protection
2021-08-17T17:50:59.8174741Z stderr F I0817 17:50:59.817153       1 controllermanager.go:574] Started "clusterrole-aggregation"
2021-08-17T17:50:59.8177222Z stderr F I0817 17:50:59.817461       1 clusterroleaggregation_controller.go:194] Starting ClusterRoleAggregator
2021-08-17T17:50:59.8177389Z stderr F I0817 17:50:59.817580       1 shared_informer.go:240] Waiting for caches to sync for ClusterRoleAggregator
2021-08-17T17:50:59.8568667Z stderr F I0817 17:50:59.856509       1 controllermanager.go:574] Started "statefulset"
2021-08-17T17:50:59.8569069Z stderr F I0817 17:50:59.856730       1 stateful_set.go:146] Starting stateful set controller
2021-08-17T17:50:59.8573777Z stderr F I0817 17:50:59.857061       1 shared_informer.go:240] Waiting for caches to sync for stateful set
2021-08-17T17:51:00.0122972Z stderr F I0817 17:51:00.011384       1 controllermanager.go:574] Started "daemonset"
2021-08-17T17:51:00.0123227Z stderr F I0817 17:51:00.011997       1 daemon_controller.go:285] Starting daemon sets controller
2021-08-17T17:51:00.012335Z stderr F I0817 17:51:00.012012       1 shared_informer.go:240] Waiting for caches to sync for daemon sets
2021-08-17T17:51:00.0173163Z stderr F I0817 17:51:00.017093       1 shared_informer.go:240] Waiting for caches to sync for resource quota
2021-08-17T17:51:00.0441045Z stderr F W0817 17:51:00.043904       1 actual_state_of_world.go:534] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="remote-control-plane" does not exist
2021-08-17T17:51:00.0465512Z stderr F I0817 17:51:00.046395       1 shared_informer.go:247] Caches are synced for TTL 
2021-08-17T17:51:00.0571065Z stderr F I0817 17:51:00.052033       1 shared_informer.go:247] Caches are synced for certificate-csrapproving 
2021-08-17T17:51:00.078911Z stderr F I0817 17:51:00.078528       1 shared_informer.go:247] Caches are synced for node 
2021-08-17T17:51:00.0789402Z stderr F I0817 17:51:00.078616       1 range_allocator.go:172] Starting range CIDR allocator
2021-08-17T17:51:00.0789537Z stderr F I0817 17:51:00.078630       1 shared_informer.go:240] Waiting for caches to sync for cidrallocator
2021-08-17T17:51:00.0789679Z stderr F I0817 17:51:00.078643       1 shared_informer.go:247] Caches are synced for cidrallocator 
2021-08-17T17:51:00.106384Z stderr F I0817 17:51:00.105728       1 shared_informer.go:247] Caches are synced for PV protection 
2021-08-17T17:51:00.1064425Z stderr F I0817 17:51:00.105805       1 range_allocator.go:373] Set node remote-control-plane PodCIDR to [10.30.0.0/24]
2021-08-17T17:51:00.1064549Z stderr F I0817 17:51:00.105813       1 shared_informer.go:247] Caches are synced for bootstrap_signer 
2021-08-17T17:51:00.1064677Z stderr F I0817 17:51:00.105853       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kubelet-client 
2021-08-17T17:51:00.1064801Z stderr F I0817 17:51:00.105867       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kubelet-serving 
2021-08-17T17:51:00.1065049Z stderr F I0817 17:51:00.105977       1 shared_informer.go:247] Caches are synced for crt configmap 
2021-08-17T17:51:00.1086326Z stderr F I0817 17:51:00.108423       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kube-apiserver-client 
2021-08-17T17:51:00.1163986Z stderr F I0817 17:51:00.112187       1 shared_informer.go:247] Caches are synced for daemon sets 
2021-08-17T17:51:00.1164865Z stderr F I0817 17:51:00.114834       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-legacy-unknown 
2021-08-17T17:51:00.1165079Z stderr F I0817 17:51:00.115041       1 shared_informer.go:247] Caches are synced for expand 
2021-08-17T17:51:00.1236873Z stderr F I0817 17:51:00.120527       1 shared_informer.go:247] Caches are synced for ClusterRoleAggregator 
2021-08-17T17:51:00.1563335Z stderr F I0817 17:51:00.148828       1 shared_informer.go:247] Caches are synced for GC 
2021-08-17T17:51:00.1563615Z stderr F I0817 17:51:00.150186       1 shared_informer.go:247] Caches are synced for PVC protection 
2021-08-17T17:51:00.1564275Z stderr F I0817 17:51:00.150419       1 shared_informer.go:247] Caches are synced for ReplicaSet 
2021-08-17T17:51:00.1564409Z stderr F I0817 17:51:00.151674       1 shared_informer.go:247] Caches are synced for HPA 
2021-08-17T17:51:00.1564542Z stderr F I0817 17:51:00.152962       1 shared_informer.go:247] Caches are synced for ReplicationController 
2021-08-17T17:51:00.1564674Z stderr F I0817 17:51:00.155423       1 shared_informer.go:247] Caches are synced for taint 
2021-08-17T17:51:00.15649Z stderr F I0817 17:51:00.155488       1 shared_informer.go:247] Caches are synced for ephemeral 
2021-08-17T17:51:00.1565385Z stderr F I0817 17:51:00.156356       1 taint_manager.go:187] "Starting NoExecuteTaintManager"
2021-08-17T17:51:00.1565528Z stderr F I0817 17:51:00.155568       1 shared_informer.go:247] Caches are synced for job 
2021-08-17T17:51:00.1567767Z stderr F I0817 17:51:00.156658       1 node_lifecycle_controller.go:1398] Initializing eviction metric for zone: 
2021-08-17T17:51:00.1569658Z stderr F W0817 17:51:00.156826       1 node_lifecycle_controller.go:1013] Missing timestamp for Node remote-control-plane. Assuming now as a timestamp.
2021-08-17T17:51:00.1571771Z stderr F I0817 17:51:00.157081       1 node_lifecycle_controller.go:1164] Controller detected that all Nodes are not-Ready. Entering master disruption mode.
2021-08-17T17:51:00.1574835Z stderr F I0817 17:51:00.157158       1 event.go:291] "Event occurred" object="remote-control-plane" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node remote-control-plane event: Registered Node remote-control-plane in Controller"
2021-08-17T17:51:00.1613121Z stderr F I0817 17:51:00.157959       1 shared_informer.go:247] Caches are synced for endpoint_slice 
2021-08-17T17:51:00.162891Z stderr F I0817 17:51:00.162696       1 shared_informer.go:240] Waiting for caches to sync for garbage collector
2021-08-17T17:51:00.1749812Z stderr F I0817 17:51:00.174665       1 shared_informer.go:247] Caches are synced for endpoint 
2021-08-17T17:51:00.1751618Z stderr F I0817 17:51:00.175001       1 shared_informer.go:247] Caches are synced for endpoint_slice_mirroring 
2021-08-17T17:51:00.189484Z stderr F I0817 17:51:00.189191       1 shared_informer.go:247] Caches are synced for attach detach 
2021-08-17T17:51:00.1930205Z stderr F I0817 17:51:00.192796       1 shared_informer.go:247] Caches are synced for TTL after finished 
2021-08-17T17:51:00.1988434Z stderr F I0817 17:51:00.198633       1 shared_informer.go:247] Caches are synced for deployment 
2021-08-17T17:51:00.2002908Z stderr F I0817 17:51:00.200093       1 shared_informer.go:247] Caches are synced for cronjob 
2021-08-17T17:51:00.2071411Z stderr F I0817 17:51:00.206984       1 shared_informer.go:247] Caches are synced for persistent volume 
2021-08-17T17:51:00.2945777Z stderr F I0817 17:51:00.294384       1 shared_informer.go:247] Caches are synced for disruption 
2021-08-17T17:51:00.2945998Z stderr F I0817 17:51:00.294433       1 disruption.go:371] Sending events to api server.
2021-08-17T17:51:00.3401397Z stderr F I0817 17:51:00.339914       1 shared_informer.go:247] Caches are synced for resource quota 
2021-08-17T17:51:00.3590836Z stderr F I0817 17:51:00.358833       1 shared_informer.go:247] Caches are synced for stateful set 
2021-08-17T17:51:00.3668076Z stderr F I0817 17:51:00.366573       1 shared_informer.go:247] Caches are synced for resource quota 
2021-08-17T17:51:00.3876371Z stderr F I0817 17:51:00.387454       1 shared_informer.go:247] Caches are synced for service account 
2021-08-17T17:51:00.3981587Z stderr F I0817 17:51:00.397846       1 shared_informer.go:247] Caches are synced for namespace 
2021-08-17T17:51:00.6298487Z stderr F I0817 17:51:00.629638       1 event.go:291] "Event occurred" object="kube-system/kindnet" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kindnet-l4dm5"
2021-08-17T17:51:00.6369877Z stderr F I0817 17:51:00.636731       1 event.go:291] "Event occurred" object="kube-system/kube-proxy" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-hbpmz"
2021-08-17T17:51:00.6968531Z stderr F E0817 17:51:00.692701       1 daemon_controller.go:320] kube-system/kindnet failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kindnet", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"c9ee2b72-d699-433c-b51e-1800ed1a138c", ResourceVersion:"262", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63764819446, loc:(*time.Location)(0x72f5420)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"kindnet", "k8s-app":"kindnet", "tier":"node"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"kubectl-create", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc0002835d8), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0002835f0)}}}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc00198a5a0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"kindnet", "k8s-app":"kindnet", "tier":"node"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"cni-cfg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc000283620), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}, v1.Volume{Name:"xtables-lock", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc000283680), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}, v1.Volume{Name:"lib-modules", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0002836b0), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"kindnet-cni", Image:"docker.io/kindest/kindnetd:v20210326-1e038dc5", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"HOST_IP", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00198a5c0)}, v1.EnvVar{Name:"POD_IP", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00198a600)}, v1.EnvVar{Name:"POD_SUBNET", Value:"10.30.0.0/16", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"CONTROL_PLANE_ENDPOINT", Value:"remote-control-plane:6443", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"cni-cfg", ReadOnly:false, MountPath:"/etc/cni/net.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"xtables-lock", ReadOnly:false, MountPath:"/run/xtables.lock", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"lib-modules", ReadOnly:true, MountPath:"/lib/modules", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc0019bc000), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0010afd28), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"kindnet", DeprecatedServiceAccount:"kindnet", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000989810), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc0011cc800)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc0010afd58)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:0, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "kindnet": the object has been modified; please apply your changes to the latest version and try again
2021-08-17T17:51:00.7297849Z stderr F E0817 17:51:00.729123       1 daemon_controller.go:320] kube-system/kube-proxy failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-proxy", GenerateName:"", Namespace:"kube-system", SelfLink:"", UID:"9d108595-0ad2-461b-8805-ba438ebc4266", ResourceVersion:"248", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63764819445, loc:(*time.Location)(0x72f5420)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kube-proxy"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"kubeadm", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc0002836e0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000283710)}}}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc00198a6a0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kube-proxy"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-proxy", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc00100b080), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}, v1.Volume{Name:"xtables-lock", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc000283728), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}, v1.Volume{Name:"lib-modules", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc000283758), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"kube-proxy", Image:"k8s.gcr.io/kube-proxy:v1.21.1", Command:[]string{"/usr/local/bin/kube-proxy", "--config=/var/lib/kube-proxy/config.conf", "--hostname-override=$(NODE_NAME)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00198a6e0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-proxy", ReadOnly:false, MountPath:"/var/lib/kube-proxy", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"xtables-lock", ReadOnly:false, MountPath:"/run/xtables.lock", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"lib-modules", ReadOnly:true, MountPath:"/lib/modules", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc0019bc060), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0010afee8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"kubernetes.io/os":"linux"}, ServiceAccountName:"kube-proxy", DeprecatedServiceAccount:"kube-proxy", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000989880), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc0011cc840)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc0010aff38)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:0, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "kube-proxy": the object has been modified; please apply your changes to the latest version and try again
2021-08-17T17:51:00.7807629Z stderr F I0817 17:51:00.778699       1 shared_informer.go:247] Caches are synced for garbage collector 
2021-08-17T17:51:00.7807923Z stderr F I0817 17:51:00.778792       1 garbagecollector.go:151] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
2021-08-17T17:51:00.8633234Z stderr F I0817 17:51:00.862917       1 shared_informer.go:247] Caches are synced for garbage collector 
2021-08-17T17:51:00.9235177Z stderr F I0817 17:51:00.920755       1 event.go:291] "Event occurred" object="local-path-storage/local-path-provisioner" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set local-path-provisioner-547f784dff to 1"
2021-08-17T17:51:00.92904Z stderr F I0817 17:51:00.925453       1 event.go:291] "Event occurred" object="kube-system/coredns" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-558bd4d5db to 2"
2021-08-17T17:51:01.1504456Z stderr F I0817 17:51:01.143069       1 event.go:291] "Event occurred" object="kube-system/coredns-558bd4d5db" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-558bd4d5db-wd7r7"
2021-08-17T17:51:01.1661164Z stderr F I0817 17:51:01.162748       1 event.go:291] "Event occurred" object="kube-system/coredns-558bd4d5db" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-558bd4d5db-hxcwx"
2021-08-17T17:51:01.1661435Z stderr F I0817 17:51:01.162788       1 event.go:291] "Event occurred" object="local-path-storage/local-path-provisioner-547f784dff" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: local-path-provisioner-547f784dff-prcrg"
2021-08-17T17:51:15.1253288Z stderr F I0817 17:51:15.125069       1 node_lifecycle_controller.go:1191] Controller detected that some Nodes are Ready. Exiting master disruption mode.
2021-08-17T17:51:16.3245654Z stderr F I0817 17:51:16.324203       1 event.go:291] "Event occurred" object="kube-system/metrics-server" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set metrics-server-99b5b5fc6 to 1"
2021-08-17T17:51:16.3376307Z stderr F I0817 17:51:16.337340       1 event.go:291] "Event occurred" object="kube-system/metrics-server-99b5b5fc6" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: metrics-server-99b5b5fc6-9qhnd"
2021-08-17T17:51:20.7531206Z stderr F I0817 17:51:20.752694       1 event.go:291] "Event occurred" object="metallb-system/speaker" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: speaker-dc9fp"
2021-08-17T17:51:20.7789855Z stderr F I0817 17:51:20.778258       1 event.go:291] "Event occurred" object="metallb-system/controller" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set controller-fb659dc8 to 1"
2021-08-17T17:51:20.8006056Z stderr F I0817 17:51:20.800216       1 event.go:291] "Event occurred" object="metallb-system/controller-fb659dc8" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: controller-fb659dc8-drf8f"
2021-08-17T17:51:20.8580184Z stderr F E0817 17:51:20.854111       1 daemon_controller.go:320] metallb-system/speaker failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"speaker", GenerateName:"", Namespace:"metallb-system", SelfLink:"", UID:"4d1cd671-2423-4b84-9ea0-6dfb201d4d67", ResourceVersion:"600", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63764819480, loc:(*time.Location)(0x72f5420)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"metallb", "component":"speaker"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"DaemonSet\",\"metadata\":{\"annotations\":{},\"labels\":{\"app\":\"metallb\",\"component\":\"speaker\"},\"name\":\"speaker\",\"namespace\":\"metallb-system\"},\"spec\":{\"selector\":{\"matchLabels\":{\"app\":\"metallb\",\"component\":\"speaker\"}},\"template\":{\"metadata\":{\"annotations\":{\"prometheus.io/port\":\"7472\",\"prometheus.io/scrape\":\"true\"},\"labels\":{\"app\":\"metallb\",\"component\":\"speaker\"}},\"spec\":{\"containers\":[{\"args\":[\"--port=7472\",\"--config=config\"],\"env\":[{\"name\":\"METALLB_NODE_NAME\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"spec.nodeName\"}}},{\"name\":\"METALLB_HOST\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"status.hostIP\"}}},{\"name\":\"METALLB_ML_BIND_ADDR\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"status.podIP\"}}},{\"name\":\"METALLB_ML_LABELS\",\"value\":\"app=metallb,component=speaker\"},{\"name\":\"METALLB_ML_NAMESPACE\",\"valueFrom\":{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"}}},{\"name\":\"METALLB_ML_SECRET_KEY\",\"valueFrom\":{\"secretKeyRef\":{\"key\":\"secretkey\",\"name\":\"memberlist\"}}}],\"image\":\"metallb/speaker:v0.9.3\",\"imagePullPolicy\":\"Always\",\"name\":\"speaker\",\"ports\":[{\"containerPort\":7472,\"name\":\"monitoring\"}],\"resources\":{\"limits\":{\"cpu\":\"100m\",\"memory\":\"100Mi\"}},\"securityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"add\":[\"NET_ADMIN\",\"NET_RAW\",\"SYS_ADMIN\"],\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true}}],\"hostNetwork\":true,\"nodeSelector\":{\"beta.kubernetes.io/os\":\"linux\"},\"serviceAccountName\":\"speaker\",\"terminationGracePeriodSeconds\":2,\"tolerations\":[{\"effect\":\"NoSchedule\",\"key\":\"node-role.kubernetes.io/master\"}]}}}}\n"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"kubectl-client-side-apply", Operation:"Update", APIVersion:"apps/v1", Time:(*v1.Time)(0xc002772078), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002772090)}}}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc00159e000), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"metallb", "component":"speaker"}, Annotations:map[string]string{"prometheus.io/port":"7472", "prometheus.io/scrape":"true"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume(nil), InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"speaker", Image:"metallb/speaker:v0.9.3", Command:[]string(nil), Args:[]string{"--port=7472", "--config=config"}, WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"monitoring", HostPort:7472, ContainerPort:7472, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"METALLB_NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00159e040)}, v1.EnvVar{Name:"METALLB_HOST", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00159e080)}, v1.EnvVar{Name:"METALLB_ML_BIND_ADDR", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00159e0c0)}, v1.EnvVar{Name:"METALLB_ML_LABELS", Value:"app=metallb,component=speaker", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"METALLB_ML_NAMESPACE", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00159e100)}, v1.EnvVar{Name:"METALLB_ML_SECRET_KEY", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00159e140)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:104857600, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100Mi", Format:"BinarySI"}}, Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"Always", SecurityContext:(*v1.SecurityContext)(0xc0028cc000), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0024a8308), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"speaker", DeprecatedServiceAccount:"speaker", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000036000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node-role.kubernetes.io/master", Operator:"", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc002224030)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc0024a8338)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:0, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "speaker": the object has been modified; please apply your changes to the latest version and try again
